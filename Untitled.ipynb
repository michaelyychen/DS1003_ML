{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"Data/MLB_2017/\"\n",
    "f = pd.read_csv(base_dir+\"MLB_PitchFX_2017_RegularSeason.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f.columns.values\n",
    "label2one = {'B':0,'S':1,'X':2}\n",
    "one2label = {0:'B', 1:'S', 2:'X'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = f[['pitcher','batter','x0','x','y','ax','ay','az','px','pz','sz_top','sz_bot',\n",
    "             'vx0','vy0','vz0','pfx_x','z0','start_speed','end_speed',\n",
    "             'break_y','break_angle','break_length','spin_dir','spin_rate']]\n",
    "train_y = f['umpcall']\n",
    "\n",
    "vfunc = np.vectorize(lambda x:label2one[x])\n",
    "data_x = train_x.as_matrix()\n",
    "data_y = train_y.as_matrix()\n",
    "data_y = vfunc(data_y)\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "data_x, data_y = shuffle(data_x, data_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_x, dev_x, train_y, dev_y = train_test_split(data_x, data_y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 2, 2, 2])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lang:\n",
    "    \"\"\"A class to summarize encoding information.\n",
    "    This class will build three dicts:\n",
    "    word2index, word2count, and index2word for\n",
    "    embedding information. Once a set of data is\n",
    "    encoded, we can transform it to corrsponding\n",
    "    indexing use the word2index, and map it back\n",
    "    using index2word.\n",
    "    Attributes:\n",
    "        word2index: A dict mapping word to index.\n",
    "        word2count: A dict mapping word to counts in the corpus.\n",
    "        index2word: A dict mapping index to word.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, name):\n",
    "        \"\"\"Init Lang with a name.\"\"\"\n",
    "        self.name = name\n",
    "        self.word2index = {\"<UNK>\": 0}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"<UNK>\"}\n",
    "        self.n_words = 1  # Count SOS and EOS\n",
    "\n",
    "    def addword(self, word):\n",
    "        \"\"\"Add a word to the dict.\"\"\"\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_lang = Lang('pitcher')\n",
    "batter_lang = Lang('batter')\n",
    "pits = train_x[:,0]\n",
    "bats = train_x[:,1]\n",
    "for i in range(len(train_x)):\n",
    "    pitch_lang.addword(pits[i])\n",
    "    batter_lang.addword(bats[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PlayerEmbedding(nn.Module):\n",
    "    \"\"\"The class for embedding records.\n",
    "    This class is for embedding the docvec (r.t, r.e, r.m)\n",
    "    into a high dimension space.\n",
    "    Attributes:\n",
    "        embedding1: embedding for r.t\n",
    "        embedding2: embedding for r.e\n",
    "        linear: A linear layer mapping [r.t, r.e, r.m] back to one space\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, pitcher_size, batter_size, embedding_dim):\n",
    "        super(PlayerEmbedding, self).__init__()\n",
    "        self.embedding1 = nn.Embedding(pitcher_size, embedding_dim)\n",
    "        self.embedding2 = nn.Embedding(batter_size, embedding_dim)\n",
    "\n",
    "    def forward(self, p, b):\n",
    "        emb_p = self.embedding1(p)\n",
    "        emb_b = self.embedding2(b)\n",
    "\n",
    "        emb_all = torch.cat([emb_p, emb_b], dim=1)\n",
    "        return emb_all\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        em_layer = [self.embedding1, self.embedding2]\n",
    "\n",
    "        for layer in em_layer:\n",
    "            layer.weight.data.normal_(0, initrange)\n",
    "\n",
    "class Fcc(nn.Module):\n",
    "    def __init__(self, hidden_size, embedding_layer, n_layers=2):\n",
    "        super(Fcc, self).__init__()\n",
    "\n",
    "        self.embedding = embedding_layer\n",
    "\n",
    "    def forward(self, X):\n",
    "        embedded = self.embedding(X[:,0], X[:,1])\n",
    "        embedded = torch.transpose(embedded, 0, 1)\n",
    "        bilstm_outs, self.hidden = self.bilstm(embedded, hidden)\n",
    "\n",
    "        output = torch.transpose(bilstm_outs, 0, 1)\n",
    "        output = torch.transpose(output, 1, 2)\n",
    "        output = F.tanh(output)\n",
    "        output = F.max_pool1d(output, output.size(2)).squeeze(2)\n",
    "\n",
    "        return output, torch.transpose(bilstm_outs, 0, 1)\n",
    "\n",
    "    def initHidden(self, batch_size):\n",
    "        forward = Variable(torch.zeros(2 * self.n_layers, batch_size, self.hidden_size // 2))\n",
    "        backward = Variable(torch.zeros(2 * self.n_layers, batch_size, self.hidden_size // 2))\n",
    "        if use_cuda:\n",
    "            return (forward.cuda(), backward.cuda())\n",
    "        else:\n",
    "            return (forward, backward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-5a1e434a537c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mv_train_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "v_train_x = Variable(torch.tensor(train_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
