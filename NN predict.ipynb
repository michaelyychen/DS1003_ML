{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature length:4\n",
      "Loading Data/MLB_2014/MLB_PitchFX_2014_RegularSeason.csv\n",
      "Loading Data/MLB_2014/MLB_PitchFX_2014_PostSeason.csv\n",
      "(658428, 7)\n",
      "(8837, 7)\n",
      "Loading Data/MLB_2015/MLB_PitchFX_2015_RegularSeason.csv\n",
      "(667265, 7)\n",
      "(672271, 7)\n",
      "Loading Data/MLB_2015/MLB_PitchFX_2015_PostSeason.csv\n",
      "(1339536, 7)\n",
      "(10277, 7)\n",
      "Loading Data/MLB_2016/MLB_PitchFX_2016_RegularSeason.csv\n",
      "(1349813, 7)\n",
      "(703809, 7)\n",
      "Loading Data/MLB_2016/MLB_PitchFX_2016_PostSeason.csv\n",
      "(2053622, 7)\n",
      "(10076, 7)\n",
      "Loading test file Data/MLB_2017/MLB_PitchFX_2017_RegularSeason.csv\n",
      "Loading test file Data/MLB_2017/MLB_PitchFX_2017_PostSeason.csv\n"
     ]
    }
   ],
   "source": [
    "base_dir = \"Data/\"\n",
    "\n",
    "label2one = {'B':0,'S':1,'X':2}\n",
    "one2label = {0:'B', 1:'S', 2:'X'}\n",
    "\n",
    "def normalize(data):\n",
    "    mu = np.mean(data, axis=0)\n",
    "    std = np.std(data, axis=0)\n",
    "    return mu, std, (data-mu)/std\n",
    "\n",
    "vfunc = np.vectorize(lambda x:label2one[x])\n",
    "\n",
    "input_labels = ['pitcher','batter', 'pitch_type','x0','x','y','ax','ay','az','px','pz','sz_top','sz_bot',\n",
    "             'vx0','vy0','vz0','pfx_x','z0','start_speed','end_speed',\n",
    "             'break_y','break_angle','break_length','spin_dir','spin_rate',\n",
    "             'inning','balls','strikes'\n",
    "             ]\n",
    "input_labels = ['pitcher','batter', 'pitch_type','balls', 'strikes','inning','pitch_count']\n",
    "#input_labels = ['pitcher','batter', \n",
    "       #'on_1b', 'on_2b', 'on_3b', 'pitch_type', 'side', \n",
    "       #'inning', 'pitch_count', 'balls', 'strikes','offense_score', 'defense_score', \n",
    "#       'ay', 'px', 'ax',  \n",
    "#       'sz_bot', 'vz0', 'vy0', 'pfx_x',\n",
    "#       'type_confidence', 'z0', 'tfs', 'pz', 'start_speed', 'az', 'zone',\n",
    "#       'break_angle', 'spin_dir', 'end_speed', 'vx0', 'sz_top', 'nasty',\n",
    "#       'pfx_z', 'break_y', 'x', 'spin_rate',\n",
    "#       'y0', 'break_length', 'y', 'x0'\n",
    "#       ]\n",
    "feature_length = len(input_labels)-3\n",
    "print(\"Feature length:{}\".format(feature_length))\n",
    "train_years = [4,5,6]\n",
    "dev_years = [7]\n",
    "\n",
    "\n",
    "train_x = {}\n",
    "train_y = {}\n",
    "ctr = 0\n",
    "for y in train_years:\n",
    "    filename= base_dir+\"MLB_201{0}/MLB_PitchFX_201{0}_RegularSeason.csv\".format(str(y))\n",
    "    print(\"Loading {}\".format(filename))\n",
    "    f = pd.read_csv(filename)\n",
    "    \n",
    "    tmp_x = f[input_labels]\n",
    "    tmp_y = f['umpcall']\n",
    "\n",
    "    tmp_x = tmp_x.as_matrix()\n",
    "    tmp_y = tmp_y.as_matrix()\n",
    "    tmp_y = vfunc(tmp_y)\n",
    "\n",
    "    if ctr==0:\n",
    "        ctr=1\n",
    "        train_x = tmp_x\n",
    "        train_y = tmp_y\n",
    "    else:\n",
    "        print(train_x.shape)\n",
    "        print(tmp_x.shape)\n",
    "        train_x = np.concatenate((train_x, tmp_x), axis=0)\n",
    "        train_y = np.concatenate((train_y, tmp_y), axis=0)\n",
    "    \n",
    "    filename= base_dir+\"MLB_201{0}/MLB_PitchFX_201{0}_PostSeason.csv\".format(str(y))\n",
    "    print(\"Loading {}\".format(filename))\n",
    "    f = pd.read_csv(filename)\n",
    "    \n",
    "    tmp_x = f[input_labels]\n",
    "    tmp_y = f['umpcall']\n",
    "\n",
    "    tmp_x = tmp_x.as_matrix()\n",
    "    tmp_y = tmp_y.as_matrix()\n",
    "    tmp_y = vfunc(tmp_y)\n",
    "    if ctr==0:\n",
    "        ctr=1\n",
    "        train_x = tmp_x\n",
    "        train_y = tmp_y\n",
    "    else:\n",
    "        print(train_x.shape)\n",
    "        print(tmp_x.shape)\n",
    "        train_x = np.concatenate((train_x, tmp_x), axis=0)\n",
    "        train_y = np.concatenate((train_y, tmp_y), axis=0)\n",
    "\n",
    "filename = base_dir+\"MLB_2017/MLB_PitchFX_2017_RegularSeason.csv\"\n",
    "print(\"Loading test file {}\".format(filename))\n",
    "f2 = pd.read_csv(filename)\n",
    "test_x = f2[input_labels]\n",
    "test_y = f2['umpcall']\n",
    "\n",
    "test_x = test_x.as_matrix()\n",
    "test_y = test_y.as_matrix()\n",
    "test_y = vfunc(test_y)\n",
    "\n",
    "filename = base_dir+\"MLB_2017/MLB_PitchFX_2017_PostSeason.csv\"\n",
    "print(\"Loading test file {}\".format(filename))\n",
    "f2 = pd.read_csv(filename)\n",
    "\n",
    "tmp_x = f2[input_labels]\n",
    "tmp_y = f2['umpcall']\n",
    "\n",
    "tmp_x = tmp_x.as_matrix()\n",
    "tmp_y = tmp_y.as_matrix()\n",
    "tmp_y = vfunc(tmp_y)\n",
    "\n",
    "test_x = np.concatenate((test_x, tmp_x), axis=0)\n",
    "test_y = np.concatenate((test_y, tmp_y), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vv = np.vectorize(lambda x: (isinstance(x, float) and math.isnan(x) ))\n",
    "idx = ~np.logical_or(vv(train_x[:,0]), vv(train_x[:,1]))\n",
    "train_x = train_x[idx]\n",
    "train_y = train_y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_x, dev_x, train_y, dev_y = train_test_split(train_x, train_y, test_size=0.1, random_state=0, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['conlead01', 'duvalad01', 'FT', 0, 1, 4, 56], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        \"\"\"Init Lang with a name.\"\"\"\n",
    "        self.name = name\n",
    "        self.word2index = {\"<UNK>\": 0}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"<UNK>\"}\n",
    "        self.n_words = 1  # Count SOS and EOS\n",
    "\n",
    "    def addword(self, word):\n",
    "        \"\"\"Add a word to the dict.\"\"\"\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map2idx(train_x, pl, bl):\n",
    "    pi = train_x[:,0]\n",
    "    vfnc = np.vectorize(lambda x: pl.word2index[x] if x in pitch_lang.word2index else 0)\n",
    "    pi = vfnc(pi).reshape(-1,1)\n",
    "    vfnc = np.vectorize(lambda x:bl.word2index[x] if x in batter_lang.word2index else 0)\n",
    "    ba = vfnc(train_x[:,1]).reshape(-1,1)\n",
    "    \n",
    "    return np.concatenate((pi,ba,train_x[:,2:]), axis=1)\n",
    "\n",
    "def data_gen(dx, df, dy, batch_size=100):\n",
    "    idx = 0\n",
    "    while True:\n",
    "        if idx*batch_size >= dx.shape[0]:\n",
    "            return\n",
    "        elif (idx+1)*batch_size > dx.shape[0]:\n",
    "            yield dx[idx*batch_size:,:], df[idx*batch_size:,:], dy[idx*batch_size:]\n",
    "        else:\n",
    "            yield dx[idx*batch_size:(idx+1)*batch_size,:], df[idx*batch_size:(idx+1)*batch_size], dy[idx*batch_size:(idx+1)*batch_size]\n",
    "        idx += 1\n",
    "\n",
    "\n",
    "def train(train_x, train_f, train_y, dev_x, dev_f, dev_y, model, optimizer, criterion, batch_size=512, max_epoch = 512, validation_interv=1000):\n",
    "    for ep in range(max_epoch):\n",
    "        print(\"Epoch {}\".format(ep))\n",
    "        train_iter = data_gen(train_x, train_f, train_y, batch_size=batch_size)\n",
    "        ctr = 0\n",
    "        avg_loss = 0\n",
    "        for bx,bf,by in train_iter:\n",
    "            optimizer.zero_grad()\n",
    "            model.train()\n",
    "            y_pred = model(bx,bf)\n",
    "            loss = criterion(y_pred, by)\n",
    "            loss.backward()\n",
    "            avg_loss += loss.item()*bx.shape[0]\n",
    "            optimizer.step()\n",
    "            ctr+= bx.shape[0]\n",
    "        #dy_pred = model(dev_x, dev_f)\n",
    "        model.eval()\n",
    "        ll = 0\n",
    "        ctrr = 0\n",
    "        acc = 0\n",
    "        for dx,df,dy in data_gen(dev_x, dev_f, dev_y, batch_size=batch_size):\n",
    "            dy_pred = model(dx, df)\n",
    "            tmp = criterion(dy_pred, dy).item()\n",
    "            ll += tmp * dx.shape[0]\n",
    "            ctrr += dx.shape[0]\n",
    "            mv, mi = torch.max(dy_pred, 1)\n",
    "            acc += torch.sum( mi == dy ).item()\n",
    "        \n",
    "        print(\"loss:{} dev_loss:{}, dev_acc:{}\".format(avg_loss/ctr, ll/ctrr, acc / ctrr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_lang = Lang('pitcher')\n",
    "batter_lang = Lang('batter')\n",
    "player_lang = Lang('player')\n",
    "pits = train_x[:,0]\n",
    "bats = train_x[:,1]\n",
    "for i in range(len(train_x)):\n",
    "    pitch_lang.addword(pits[i])\n",
    "    batter_lang.addword(bats[i])\n",
    "    player_lang.addword(pits[i])    \n",
    "    player_lang.addword(bats[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vtx = Variable(torch.from_numpy(map2idx(train_x[:,:2], player_lang, player_lang).astype(np.long))).cuda()\n",
    "vtf = Variable(torch.from_numpy(train_x[:,3:].astype(np.float32))).cuda()\n",
    "vty = Variable(torch.from_numpy(train_y)).cuda()\n",
    "vdx = Variable(torch.from_numpy(map2idx(dev_x[:,:2], player_lang, player_lang).astype(np.long))).cuda()\n",
    "vdf = Variable(torch.from_numpy(dev_x[:,3:].astype(np.float32))).cuda()\n",
    "vdy = Variable(torch.from_numpy(dev_y)).cuda()\n",
    "\n",
    "vtestx = Variable(torch.from_numpy(map2idx(test_x[:,:2], player_lang, player_lang).astype(np.long))).cuda()\n",
    "vtestf = Variable(torch.from_numpy(test_x[:,3:].astype(np.float32))).cuda()\n",
    "vtesty = Variable(torch.from_numpy(test_y)).cuda()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fcc(nn.Module):\n",
    "    def __init__(self, p=0.1):\n",
    "        super(Fcc, self).__init__()\n",
    "        self.drop1 = nn.Dropout(p)\n",
    "        self.drop2 = nn.Dropout(p)\n",
    "        self.drop3 = nn.Dropout(p)\n",
    "        self.drop4 = nn.Dropout(p)\n",
    "        #self.drop3 = nn.Dropout(p)\n",
    "        self.lin1 = nn.Linear(feature_length, 300)\n",
    "        self.act1 = nn.PReLU()\n",
    "        self.lin2 = nn.Linear(300, 300)\n",
    "        self.act2 = F.tanh\n",
    "        self.lin3 = nn.Linear(300, 200)\n",
    "        self.act3 = F.sigmoid\n",
    "        self.lin4 = nn.Linear(200, 100)\n",
    "        self.act4 = nn.SELU()\n",
    "        self.lin5 = nn.Linear(100, 3)\n",
    "        #self.lin4 = nn.Linear(100, 3)\n",
    "\n",
    "    def forward(self, players, features):\n",
    "        #embedded = self.embedding(players[:,0], players[:,1])\n",
    "        #output = torch.cat([embedded, features], dim=1)\n",
    "        #output = self.drop_emb(output)\n",
    "        output = features\n",
    "        \n",
    "        output = self.lin1(output)\n",
    "        output = self.act1(output)\n",
    "        output = self.drop1(output)\n",
    "        \n",
    "        output = self.lin2(output)\n",
    "        output = self.act2(output)\n",
    "        output = self.drop2(output)\n",
    "        \n",
    "        output = self.lin3(output)\n",
    "        output = self.act3(output)\n",
    "        output = self.drop3(output)\n",
    "        \n",
    "        output = self.lin4(output)\n",
    "        output = self.act4(output)\n",
    "        output = self.drop4(output)\n",
    "        \n",
    "        output = self.lin5(output)\n",
    "        #output = F.relu(output)\n",
    "        #output = self.drop3(output)\n",
    "        \n",
    "        #output = self.lin4(output)\n",
    "        \n",
    "        output = F.log_softmax(output, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fcc(\n",
      "  (drop1): Dropout(p=0.1)\n",
      "  (drop2): Dropout(p=0.1)\n",
      "  (drop3): Dropout(p=0.1)\n",
      "  (drop4): Dropout(p=0.1)\n",
      "  (lin1): Linear(in_features=4, out_features=300, bias=True)\n",
      "  (act1): PReLU(num_parameters=1)\n",
      "  (lin2): Linear(in_features=300, out_features=300, bias=True)\n",
      "  (lin3): Linear(in_features=300, out_features=200, bias=True)\n",
      "  (lin4): Linear(in_features=200, out_features=100, bias=True)\n",
      "  (act4): SELU()\n",
      "  (lin5): Linear(in_features=100, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = Fcc(0.1).cuda()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "loss:1.0631074991370213 dev_loss:1.0406603813171387, dev_acc:0.4599118088869506\n",
      "Epoch 1\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (2) : out of memory at /home/yhhuang/code/tools/pytorch/aten/src/THC/generic/THCStorage.cu:58",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-346a06a5aa53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#crit = nn.NLLLoss(torch.FloatTensor([0.3,0.3,0.4]).cuda())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcrit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNLLLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvtf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvdx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvdy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4096\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-33f71bc07d2c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_x, train_f, train_y, dev_x, dev_f, dev_y, model, optimizer, criterion, batch_size, max_epoch, validation_interv)\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-22364afe13e9>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, players, features)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/dropout.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/_functions/dropout.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(cls, ctx, input, p, train, inplace)\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbernoulli_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (2) : out of memory at /home/yhhuang/code/tools/pytorch/aten/src/THC/generic/THCStorage.cu:58"
     ]
    }
   ],
   "source": [
    "opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "#crit = nn.NLLLoss(torch.FloatTensor([0.3,0.3,0.4]).cuda())\n",
    "crit = nn.NLLLoss()\n",
    "train(vtx, vtf, vty, vdx, vdf, vdy, model, opt, crit, max_epoch=10, batch_size=4096*64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train(vtx, vtf, vty, vdx, vdf, vdy, model, opt, crit, max_epoch=100, batch_size=4096*64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlayerEmbedding(nn.Module):\n",
    "    \"\"\"The class for embedding records.\n",
    "    This class is for embedding the docvec (r.t, r.e, r.m)\n",
    "    into a high dimension space.\n",
    "    Attributes:\n",
    "        embedding1: embedding for r.t\n",
    "        embedding2: embedding for r.e\n",
    "        linear: A linear layer mapping [r.t, r.e, r.m] back to one space\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, pitcher_size, batter_size, embedding_dim):\n",
    "        super(PlayerEmbedding, self).__init__()\n",
    "        self.embedding1 = nn.Embedding(pitcher_size, embedding_dim)\n",
    "        self.embedding2 = nn.Embedding(batter_size, embedding_dim)\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "    def forward(self, p, b):\n",
    "        emb_p = self.embedding1(p)\n",
    "        emb_b = self.embedding2(b)\n",
    "\n",
    "        emb_all = torch.cat([emb_p, emb_b], dim=1)\n",
    "        return emb_all\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        em_layer = [self.embedding1, self.embedding2]\n",
    "\n",
    "        for layer in em_layer:\n",
    "            layer.weight.data.normal_(0, initrange)\n",
    "\n",
    "class Fcc(nn.Module):\n",
    "    def __init__(self, embedding_layer):\n",
    "        super(Fcc, self).__init__()\n",
    "        p=0.1\n",
    "        self.embedding = embedding_layer\n",
    "        self.drop_emb = nn.Dropout(p)\n",
    "        self.drop1 = nn.Dropout(p)\n",
    "        self.drop2 = nn.Dropout(p)\n",
    "        self.drop3 = nn.Dropout(p)\n",
    "        self.drop4 = nn.Dropout(p)\n",
    "        self.lin1 = nn.Linear(2*self.embedding.embedding_dim + feature_length, 300)\n",
    "        self.act1 = nn.SELU()\n",
    "        self.lin2 = nn.Linear(300, 300)\n",
    "        self.act2 = nn.SELU()\n",
    "        self.lin3 = nn.Linear(300, 300)\n",
    "        \n",
    "        self.act3 = nn.SELU()\n",
    "        self.lin4 = nn.Linear(300, 300)\n",
    "        self.act4 = nn.SELU()\n",
    "        self.lin5 = nn.Linear(300, 3)\n",
    "        #self.lin4 = nn.Linear(100, 3)\n",
    "\n",
    "    def forward(self, players, features):\n",
    "        embedded = self.embedding(players[:,0], players[:,1])\n",
    "        output = torch.cat([embedded, features], dim=1)\n",
    "        output = self.drop_emb(output)\n",
    "        \n",
    "        output = self.lin1(output)\n",
    "        output = self.act1(output)\n",
    "        output = self.drop1(output)\n",
    "        \n",
    "        output = self.lin2(output)\n",
    "        output = self.act2(output)\n",
    "        output = self.drop2(output)\n",
    "        \n",
    "        output = self.lin3(output)\n",
    "        output = self.act3(output)\n",
    "        output = self.drop3(output)\n",
    "        \n",
    "        output = self.lin4(output)\n",
    "        output = self.act4(output)\n",
    "        #output = self.drop4(output)\n",
    "        \n",
    "        output = self.lin5(output)\n",
    "        \n",
    "        output = F.log_softmax(output, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_layer = PlayerEmbedding(pitch_lang.n_words,batter_lang.n_words, 30).cuda()\n",
    "model = Fcc(emb_layer).cuda()\n",
    "print(model)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "crit = nn.NLLLoss()\n",
    "train(vtx, vtf, vty, vdx, vdf, vdy, model, opt, crit, max_epoch=40, batch_size=4096*8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fcc(\n",
      "  (embedding): PlayerEmbedding(\n",
      "    (embedding1): Embedding(1073, 30)\n",
      "    (embedding2): Embedding(1409, 30)\n",
      "  )\n",
      "  (drop_emb): Dropout(p=0.2)\n",
      "  (drop1): Dropout(p=0.2)\n",
      "  (drop2): Dropout(p=0.2)\n",
      "  (lin1): Linear(in_features=64, out_features=600, bias=True)\n",
      "  (act1): SELU()\n",
      "  (lin2): Linear(in_features=600, out_features=200, bias=True)\n",
      "  (act2): SELU()\n",
      "  (lin3): Linear(in_features=200, out_features=3, bias=True)\n",
      ")\n",
      "Epoch 0\n",
      "loss:1.0123226479305996 dev_loss:1.0152487630800677, dev_acc:0.47003440422542037\n",
      "Epoch 1\n",
      "loss:1.0123535767819545 dev_loss:1.015065942760493, dev_acc:0.4702573048408199\n",
      "Epoch 2\n",
      "loss:1.0121118442589532 dev_loss:1.0153059340368993, dev_acc:0.46958375732906915\n",
      "Epoch 3\n",
      "loss:1.0121334053785038 dev_loss:1.0154151142709285, dev_acc:0.46973397296118624\n",
      "Epoch 4\n",
      "loss:1.0122638532102688 dev_loss:1.0152626026310407, dev_acc:0.47052866211174105\n",
      "Epoch 5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-86180e105840>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvtf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvdx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvdy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4096\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-fc95997b0ad2>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_x, train_f, train_y, dev_x, dev_f, dev_y, model, optimizer, criterion, batch_size, max_epoch, validation_interv)\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m             \u001b[0mavg_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     87\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     88\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(model)\n",
    "train(vtx, vtf, vty, vdx, vdf, vdy, model, opt, crit, max_epoch=100, batch_size=4096*16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_layer = PlayerEmbedding(pitch_lang.n_words,batter_lang.n_words, 500).cuda()\n",
    "emb_layer.load_state_dict(torch.load('shallow_post.pt.emb'))\n",
    "model = Fcc(emb_layer).cuda()\n",
    "model.load_state_dict(torch.load('shallow_post.pt.model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'shallow_post.pt.model')\n",
    "torch.save(emb_layer.state_dict(), 'shallow_post.pt.emb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def generate_confusion_matrix(y_test, y_train, file_name = \"confusion_matrix.png\"):\n",
    "    ax= plt.subplot()\n",
    "    cm = confusion_matrix(y_test, y_train)\n",
    "    df_cm = pd.DataFrame(cm, range(3), range(3))\n",
    "    sn.set(font_scale=1.2)#for label size\n",
    "    sn.heatmap(df_cm, annot=True, fmt=\"d\",annot_kws={\"size\": 14}, cmap=\"YlGnBu\")\n",
    "#     ax.set_title('Confusion Matrix');\n",
    "    ax.xaxis.set_ticklabels(['Ball', 'Strike', 'Hit']) \n",
    "    ax.yaxis.set_ticklabels(['Ball', 'Strike', 'Hit'])\n",
    "    #plt.savefig(file_name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:9: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "criter = nn.NLLLoss()\n",
    "with torch.no_grad():\n",
    "    ll=0\n",
    "    ctrr=0\n",
    "    crit=nn.NLLLoss()\n",
    "    for dx,df,dy in data_gen(vtestx, vtestf, vtesty, batch_size=128):\n",
    "        model.eval()\n",
    "        dy_pred = model(dx, df)\n",
    "        tmp = criter(dy_pred, dy).data[0]\n",
    "        ll += tmp * dx.shape[0]\n",
    "        ctrr += dx.shape[0]\n",
    "    dev_loss = ll.item()/ctrr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    ll=0\n",
    "    ctrr=0\n",
    "    pred = []\n",
    "    for dx,df,dy in data_gen(vtestx, vtestf, vtesty, batch_size=128):\n",
    "        model.eval()\n",
    "        dy_pred = model(dx, df)\n",
    "        _,py = torch.max(dy_pred, 1)\n",
    "        ll += torch.sum(py==dy)\n",
    "        pred.append(py.cpu().data)\n",
    "        ctrr += dx.shape[0]\n",
    "    dev_acc = ll.item()/ctrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = torch.cat(pred).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fcc(\n",
      "  (embedding): PlayerEmbedding(\n",
      "    (embedding1): Embedding(1073, 30)\n",
      "    (embedding2): Embedding(1409, 30)\n",
      "  )\n",
      "  (drop_emb): Dropout(p=0.2)\n",
      "  (drop1): Dropout(p=0.2)\n",
      "  (drop2): Dropout(p=0.2)\n",
      "  (lin1): Linear(in_features=64, out_features=600, bias=True)\n",
      "  (act1): SELU()\n",
      "  (lin2): Linear(in_features=600, out_features=200, bias=True)\n",
      "  (act2): SELU()\n",
      "  (lin3): Linear(in_features=200, out_features=3, bias=True)\n",
      ")\n",
      "test loss: 1.0139234410259232 dev_los: 0.4691603830700644\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEGCAYAAABiq/5QAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f99e3878668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(model)\n",
    "print(\"test loss: {} dev_los: {}\".format(dev_loss, dev_acc))\n",
    "generate_confusion_matrix(test_y, pred_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepModel\n",
    "\n",
    "----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlayerStat:\n",
    "    def __init__(self, train_x):\n",
    "        self.types = list(set(train_x[:,2]))\n",
    "        self.pitchers = list(set(train_x[:,0]))\n",
    "        self.batters = list(set(train_x[:,1]))\n",
    "        self.type_dist = {}\n",
    "        self.type_sum = {}\n",
    "        self.feat_dim = train_x.shape[1]-3\n",
    "        for i in range(train_x.shape[0]):\n",
    "            p = train_x[i,0]\n",
    "            b = train_x[i,1]\n",
    "            t = train_x[i,2]\n",
    "            self.addWord(p+' '+b, t, train_x[i,3:])\n",
    "            self.addWord(p, t, train_x[i,3:])\n",
    "            self.addWord(b, t, train_x[i,3:])\n",
    "            self.addWord('<TOTAL>', t, train_x[i,3:])\n",
    "    def addWord(self, label, t, data):\n",
    "        if label not in self.type_dist:\n",
    "            self.type_dist[label] = {}\n",
    "            self.type_sum[label] = {}\n",
    "            for tt in self.types:\n",
    "                self.type_dist[label][tt]=0\n",
    "                self.type_sum[label][tt] = np.zeros((1,self.feat_dim))\n",
    "        self.type_dist[label][t] +=1\n",
    "        self.type_sum[label][t] += data.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PlayerStat(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictd(self, X, model):\n",
    "    model.eval()\n",
    "    pred_y = np.zeros((X.shape[0], 3))\n",
    "    for i in range(X.shape[0]):\n",
    "        p = str(X[i,0])\n",
    "        b = str(X[i,1])\n",
    "        inp_mat = np.zeros((len(self.types), self.feat_dim))\n",
    "        if p+' '+b in self.type_dist:\n",
    "            for j in range(len(self.types)):\n",
    "                tp = self.types[j]\n",
    "                inp_mat[j,:] = self.type_sum[p+' '+b][tp] / self.type_dist[p+' '+b][tp]\n",
    "                inp_mat[j, -3:] = X[i, -3:]\n",
    "            vx = Variable(torch.from_numpy(map2idx(np.asarray([[p,b]]*len(self.types))).astype(np.long))).cuda()\n",
    "            vf = Variable(torch.from_numpy( inp_mat.astype(np.float32) )).cuda()\n",
    "            pp = model(vx,vf)\n",
    "            pp = pp.exp().cpu().data.numpy()\n",
    "            ctr = 0\n",
    "            for j in range(len(self.types)):\n",
    "                pred_y[i,:]+=pp[j,:] * self.type_dist[p+' '+b][self.types[j]]\n",
    "                ctr += self.type_dist[p+' '+b][self.types[j]]\n",
    "            pred_y[i,:] /= ctr\n",
    "        elif p in self.type_dist:\n",
    "            for j in range(len(self.types)):\n",
    "                tp = self.types[j]\n",
    "                inp_mat[j,:] = self.type_sum[p][tp] / self.type_dist[p][tp]\n",
    "                inp_mat[j, -3:] = X[i, -3:]\n",
    "                \n",
    "            vx = Variable(torch.from_numpy(map2idx(np.asarray([[p,'<UNK>']]*len(self.types))).astype(np.long))).cuda()\n",
    "            vf = Variable(torch.from_numpy( inp_mat.astype(np.float32) )).cuda()\n",
    "            pp = model(vx,vf)\n",
    "            pp = pp.exp().cpu().data.numpy()\n",
    "\n",
    "            ctr = 0\n",
    "            for j in range(len(self.types)):\n",
    "                pred_y[i,:]+=pp[j,:] * self.type_dist[p][self.types[j]]\n",
    "                ctr += self.type_dist[p][self.types[j]]\n",
    "            pred_y[i,:] /= ctr\n",
    "\n",
    "        elif b in self.type_dist:\n",
    "            for j in range(len(self.types)):\n",
    "                tp = self.types[j]\n",
    "                inp_mat[j,:] = self.type_sum[b][tp] / self.type_dist[b][tp]\n",
    "                inp_mat[j, -3:] = X[i, -3:]\n",
    "                \n",
    "            vx = Variable(torch.from_numpy(map2idx(np.asarray([['<UNK>',b]]*len(self.types))).astype(np.long))).cuda()\n",
    "            vf = Variable(torch.from_numpy( inp_mat.astype(np.float32) )).cuda()\n",
    "            pp = model(vx,vf)\n",
    "            pp = pp.exp().cpu().data.numpy()\n",
    "\n",
    "            ctr = 0\n",
    "            for j in range(len(self.types)):\n",
    "                pred_y[i,:]+=pp[j,:] * self.type_dist[b][self.types[j]]\n",
    "                ctr += self.type_dist[b][self.types[j]]\n",
    "            pred_y[i,:] /= ctr\n",
    "        else:\n",
    "            for j in range(len(self.types)):\n",
    "                tp = self.types[j]\n",
    "                inp_mat[j,:] = self.type_sum['<TOTAL>'][tp] / self.type_dist['<TOTAL>'][tp]\n",
    "                inp_mat[j, -3:] = X[i, -3:]\n",
    "                \n",
    "            vx = Variable(torch.from_numpy(map2idx(np.asarray([['<UNK>','<UNK>']]*len(self.types))).astype(np.long))).cuda()\n",
    "            vf = Variable(torch.from_numpy( inp_mat.astype(np.float32) )).cuda()\n",
    "            pp = model(vx,vf)\n",
    "            pp = pp.exp().cpu().data.numpy()\n",
    "\n",
    "            ctr = 0\n",
    "            for j in range(len(self.types)):\n",
    "                pred_y[i,:]+=pp[j,:] * self.type_dist['<TOTAL>'][self.types[j]]\n",
    "                ctr += self.type_dist['<TOTAL>'][self.types[j]]\n",
    "            pred_y[i,:] /= ctr\n",
    "    return pred_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = predictd(ps, test_x, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.argmax(pred, axis=1) == test_y) / test_y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion(pred, y):\n",
    "    s = 0;\n",
    "    for i in range(pred.shape[0]):\n",
    "        s -= np.log(pred[i,y[i]])\n",
    "    return s/y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion(pred, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cf = confusion_matrix(test_y, pred_y) / test_y.shape[0]\n",
    "print(cf)\n",
    "plt.matshow(cf, vmin=0, vmax=1)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlayerEmbedding(nn.Module):\n",
    "    def __init__(self, pitcher_size, batter_size, embedding_dim):\n",
    "        super(PlayerEmbedding, self).__init__()\n",
    "        self.embedding1 = nn.Embedding(pitcher_size, embedding_dim)\n",
    "        self.embedding2 = nn.Embedding(batter_size, embedding_dim)\n",
    "        self.out_dim = embedding_dim*16\n",
    "        self.conv1 = nn.Conv1d(2,32,1, padding=0)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(32,32,1, padding=0)\n",
    "        self.conv3 = nn.Conv1d(32,32,1, padding=0)\n",
    "        self.maxpol = nn.MaxPool1d(2)\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "    def forward(self, p, b):\n",
    "        emb_p = self.embedding1(p)\n",
    "        emb_b = self.embedding2(b)\n",
    "        emb_p = emb_p.unsqueeze(1)\n",
    "        emb_b = emb_b.unsqueeze(1)\n",
    "\n",
    "        emb_all = torch.cat([emb_p, emb_b], dim=1)\n",
    "        bypass = F.relu(self.conv1(emb_all))\n",
    "        \n",
    "        emb_all = F.relu(self.conv2(bypass))\n",
    "        emb_all = F.relu(self.conv3(emb_all))\n",
    "        emb_all += bypass\n",
    "        emb_all = self.maxpol(emb_all)\n",
    "        emb_all = emb_all.view(emb_all.shape[0],-1)\n",
    "        \n",
    "        return emb_all\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        em_layer = [self.embedding1, self.embedding2]\n",
    "\n",
    "        for layer in em_layer:\n",
    "            #layer.weight.data.normal_(0, initrange)\n",
    "            layer.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, in_dim):\n",
    "        super(ResNet, self).__init__()\n",
    "\n",
    "        self.lin1 = nn.Linear(in_dim, in_dim)\n",
    "        self.lin2 = nn.Linear(in_dim, in_dim)\n",
    "    def forward(self, x):\n",
    "        output = F.relu(self.lin1(x))\n",
    "        return self.lin2(output) + x\n",
    "class Fcc(nn.Module):\n",
    "    def __init__(self, embedding_layer):\n",
    "        super(Fcc, self).__init__()\n",
    "\n",
    "        self.embedding = embedding_layer\n",
    "        #hid_dim = [100,100,100,100,100]\n",
    "        p = 0.0\n",
    "        res_dim=1024\n",
    "        expand_fea_dim = 64\n",
    "\n",
    "        self.bn = torch.nn.BatchNorm1d(feature_length)\n",
    "        #self.drop1 = nn.Dropout(p)\n",
    "        #self.lin1 = nn.Linear(2*self.embedding.embedding_dim + 22, hid_dim[0])\n",
    "\n",
    "        self.fea1 = nn.Linear(feature_length,64)\n",
    "        #self.feadrop1 = nn.Dropout(p)\n",
    "        self.feares2 = ResNet(64)\n",
    "        #self.feadrop2 = nn.Dropout(p)\n",
    "        self.fea3 = nn.Linear(64,expand_fea_dim)\n",
    "\n",
    "        self.lin1 = nn.Linear(self.embedding.out_dim + expand_fea_dim, res_dim)\n",
    "        #self.lin1 = nn.Linear(2*self.embedding.embedding_dim, hid_dim[0])\n",
    "        #self.drop2 = nn.Dropout(p)\n",
    "        self.res2 = ResNet(res_dim)\n",
    "        #self.drop3 = nn.Dropout(p)\n",
    "        self.res3 = ResNet(res_dim)\n",
    "        #self.drop4 = nn.Dropout(p)\n",
    "\n",
    "        self.lin3 = nn.Linear(res_dim, 256)\n",
    "\n",
    "        self.res4 = ResNet(256)\n",
    "        #self.drop5 = nn.Dropout(p)\n",
    "        self.res5 = ResNet(256)\n",
    "        #self.drop6 = nn.Dropout(p)\n",
    "        #self.lin6 = nn.Linear(256, 64)\n",
    "        #self.lin7 = nn.Linear(64,64)\n",
    "        self.lin8 = nn.Linear(256,3)\n",
    "    \n",
    "    def forward(self, players, features):\n",
    "        embedded = F.relu(self.embedding(players[:,0], players[:,1]))\n",
    "        fea = self.bn(features)\n",
    "        fea = F.relu(self.fea1(fea))\n",
    "        #fea = self.feadrop1(fea)\n",
    "        fea = F.relu(self.feares2(fea))\n",
    "        #fea = self.feadrop2(fea)\n",
    "        fea = F.relu(self.fea3(fea))\n",
    "        output = torch.cat([embedded, fea], dim=1)\n",
    "        #output = embedded\n",
    "\n",
    "        #output = self.drop1(output)\n",
    "        output = self.lin1(output)\n",
    "        output = F.relu(output)\n",
    "        \n",
    "        #output = self.drop2(output)\n",
    "        output = self.res2(output)\n",
    "        output = F.relu(output)\n",
    "        \n",
    "        #output = self.drop3(output)\n",
    "        output = self.res3(output)\n",
    "        output = F.relu(output)\n",
    "        \n",
    "        output = F.relu(self.lin3(output))\n",
    "\n",
    "        #output = self.drop4(output)\n",
    "        output = self.res4(output)\n",
    "        output = F.relu(output)\n",
    "\n",
    "        #output = self.drop5(output)\n",
    "        output = self.res5(output)\n",
    "        output = F.relu(output)\n",
    "\n",
    "        #output = self.lin6(output)\n",
    "        #output = F.relu(output)\n",
    "        #output = self.lin7(output)\n",
    "        #output = F.relu(output)\n",
    "\n",
    "        output = self.lin8(output)\n",
    "        output = F.log_softmax(output, dim=1)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_layer = PlayerEmbedding(pitch_lang.n_words,batter_lang.n_words, 100).cuda()\n",
    "model = Fcc(emb_layer).cuda()\n",
    "print(model)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "crit = nn.NLLLoss()\n",
    "train(vtx, vtf, vty, vdx, vdf, vdy, model, opt, crit, max_epoch=5, batch_size=2048, validation_interv=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(vtx, vtf, vty, vdx, vdf, vdy, model, opt, crit, max_epoch=5, batch_size=2048, validation_interv=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_layer_15 = PlayerEmbedding(pitch_lang.n_words,batter_lang.n_words, 100).cuda()\n",
    "emb_layer_15.load_state_dict(emb_layer.state_dict())\n",
    "model_15 = Fcc(emb_layer_15).cuda()\n",
    "model_15.load_state_dict(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_15.eval()\n",
    "ctrr=0\n",
    "ll=0\n",
    "for dx,df,dy in data_gen(vtestx, vtestf, vtesty, batch_size=128):\n",
    "    dy_pred = model_15(dx, df)\n",
    "    pred_y = dy_pred.cpu().data.numpy()\n",
    "    tmp = np.sum(np.argmax(pred_y,axis=1) == dy.cpu().data.numpy()) / dx.shape[0]\n",
    "    ll += tmp * dx.shape[0]\n",
    "    ctrr += dx.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll / ctrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_15.eval()\n",
    "ctrr=0\n",
    "ll=0\n",
    "for dx,df,dy in data_gen(vtestx, vtestf, vtesty, batch_size=128):\n",
    "    dy_pred = model_15(dx, df)\n",
    "    tmp = crit(dy_pred, dy).data[0]\n",
    "    ll += tmp * dx.shape[0]\n",
    "    ctrr += dx.shape[0]\n",
    "ll/ctrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = []\n",
    "for dx,df,dy in data_gen(vtestx, vtestf, vtesty, batch_size=128):\n",
    "    dy_pred = model_15(dx, df)\n",
    "    pred_y = dy_pred.cpu().data.numpy()\n",
    "    pred.append(np.argmax(pred_y, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_l = pred[0]\n",
    "for i in range(1,len(pred)):\n",
    "    pred_l = np.concatenate((pred_l, pred[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(test_y, pred_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = predictd(ps, test_x, model_15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.argmax(pred, axis=1) == test_y) / test_y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion(pred, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(test_y, np.argmax(pred, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3\n",
    "\n",
    "Learn only from previous available data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_layer = PlayerEmbedding(pitch_lang.n_words,batter_lang.n_words, 100).cuda()\n",
    "model2 = Fcc(emb_layer).cuda()\n",
    "print(model2)\n",
    "opt = torch.optim.Adam(model2.parameters(), lr=1e-3)\n",
    "crit = nn.NLLLoss()\n",
    "train(vtx, vtf, vty, vdx, vdf, vdy, model2, opt, crit, max_epoch=5, batch_size=2048, validation_interv=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(vtx, vtf, vty, vdx, vdf, vdy, model2, opt, crit, max_epoch=5, batch_size=2048, validation_interv=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_layer_5 = PlayerEmbedding(pitch_lang.n_words,batter_lang.n_words, 100).cuda()\n",
    "emb_layer_5.load_state_dict(emb_layer.state_dict())\n",
    "model_5 = Fcc(emb_layer_5).cuda()\n",
    "model_5.load_state_dict(model2.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5.eval()\n",
    "ctrr=0\n",
    "ll=0\n",
    "for dx,df,dy in data_gen(vtestx, vtestf, vtesty, batch_size=128):\n",
    "    dy_pred = model_5(dx, df)\n",
    "    pred_y = dy_pred.cpu().data.numpy()\n",
    "    tmp = np.sum(np.argmax(pred_y,axis=1) == dy.cpu().data.numpy()) / dx.shape[0]\n",
    "    ll += tmp * dx.shape[0]\n",
    "    ctrr += dx.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll / ctrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5.eval()\n",
    "ctrr=0\n",
    "ll=0\n",
    "for dx,df,dy in data_gen(vtestx, vtestf, vtesty, batch_size=128):\n",
    "    dy_pred = model_5(dx, df)\n",
    "    tmp = crit(dy_pred, dy).data[0]\n",
    "    ll += tmp * dx.shape[0]\n",
    "    ctrr += dx.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll/ctrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "model_5.eval()\n",
    "ctrr=0\n",
    "ll=np.zeros((3,3))\n",
    "for dx,df,dy in data_gen(vtestx, vtestf, vtesty, batch_size=128):\n",
    "    dy_pred = model_5(dx, df)\n",
    "    pred_y = np.argmax(dy_pred.cpu().data.numpy(), axis=1)\n",
    "    tmp = confusion_matrix(pred_y, dy.cpu().data.numpy())\n",
    "    ll += tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(1 == test_y) / test_y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dum_pred = np.zeros((test_y.shape[0],3))\n",
    "pad = 3.333333333333333333e-1\n",
    "dum_pred[:, 1] = 1 - 2*pad\n",
    "dum_pred[:,0] = pad\n",
    "dum_pred[:,2] = pad\n",
    "criterion(dum_pred, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(test_y, np.argmax(dum_pred, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result\n",
    "Here are some of the result on the dataset\n",
    "\n",
    "training: 2015,2016,2017 regular season\n",
    "\n",
    "dev: 0.1 of the training set\n",
    "\n",
    "test: 2017 post season"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline\n",
    "We can simply predict the output to be all 1 as the 'S' is the most outcome in our training data. The accuracy of this simple prediction function is:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy on the test set is: 0.47999643589058183\n",
    "\n",
    "The cross-entropy on the test set is: 1.0986122886679723\n",
    "\n",
    "The confusion matrix is:\n",
    "```text\n",
    "array([[   0, 4009,    0],\n",
    "       [   0, 5387,    0],\n",
    "       [   0, 1827,    0]])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cross-entropy of this model is actually affected by the probability assigned to the other two classes(class 0 and 2). The minimum cross-entropy is: 1.0986122886679723"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shallow NN w/ Post + Avg. Gen.\n",
    "In this model, we first train our shallow Net with data including the post pitch features. And use a generative model to make the prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use all of the following features as our input:\n",
    "``` text\n",
    "'pitcher','batter', 'pitch_type','x0','x','y','ax','ay','az','px','pz','sz_top','sz_bot',\n",
    " 'vx0','vy0','vz0','pfx_x','z0','start_speed','end_speed',\n",
    " 'break_y','break_angle','break_length','spin_dir','spin_rate',\n",
    " 'inning','balls','strikes'```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the structure of the shallow NN:\n",
    "```text\n",
    "Fcc(\n",
    "  (embedding): PlayerEmbedding(\n",
    "    (embedding1): Embedding(1120, 100)\n",
    "    (embedding2): Embedding(1445, 100)\n",
    "  )\n",
    "  (drop1): Dropout(p=0.1)\n",
    "  (lin1): Linear(in_features=225, out_features=100, bias=True)\n",
    "  (lin2): Linear(in_features=100, out_features=100, bias=True)\n",
    "  (lin3): Linear(in_features=100, out_features=50, bias=True)\n",
    "  (lin4): Linear(in_features=50, out_features=3, bias=True)\n",
    ")```\n",
    "After 30 epoch of training:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy on the test set is: 0.7106440969731745\n",
    "\n",
    "The cross-entropy on the test set is: 0.6153840772368059\n",
    "\n",
    "The confusion matrix is:\n",
    "```text\n",
    "array([[3276,  721,   12],\n",
    "       [ 658, 4446,  283],\n",
    "       [  92, 1446,  289]])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One observation is that the 'X'(2) classes is likely to be predicted as 'S'(1). This coincide to our knowledge of the baseball."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Generation Model\n",
    "Since we do not have most of the pitch/fx features. We average the feature from the training data grouped by pitcher,batter and pitch_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy on the test set is: 0.450325224984407\n",
    "\n",
    "The cross-entropy on the test set is: 1.7214855619830554\n",
    "\n",
    "The confusion matrix is:\n",
    "```text\n",
    "array([[  99, 3454,  456],\n",
    "       [ 124, 4656,  607],\n",
    "       [  30, 1498,  299]])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the confusion matrix, we can see that most of the prediction is 'S'. This might be dut to we are averaging dataset to generate input and most entries in the dataset are 'S'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shallow NN w/o Post Features\n",
    "We use the same structure as the previous model but with only the input features:\n",
    "```text\n",
    "'pitcher','batter','balls', 'strikes','inning','pitch_count'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy on the test set is: 0.47042509443886577\n",
    "\n",
    "The cross-entropy on the test set is: 0.9997494564191931\n",
    "\n",
    "The confusion matrix is:\n",
    "```text\n",
    "array([[ 928, 3066,   15],\n",
    "       [ 866, 4489,   32],\n",
    "       [ 326, 1485,   16]])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Model w/ Post + Avg. Gen\n",
    "We follow the same procedure in the shallow model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use all of the following features as our input:\n",
    "``` text\n",
    "'pitcher','batter', 'pitch_type','x0','x','y','ax','ay','az','px','pz','sz_top','sz_bot',\n",
    " 'vx0','vy0','vz0','pfx_x','z0','start_speed','end_speed',\n",
    " 'break_y','break_angle','break_length','spin_dir','spin_rate',\n",
    " 'inning','balls','strikes'```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```text\n",
    "Fcc(\n",
    "  (embedding): PlayerEmbedding(\n",
    "    (embedding1): Embedding(1120, 100)\n",
    "    (embedding2): Embedding(1445, 100)\n",
    "    (conv1): Conv1d(2, 32, kernel_size=(1,), stride=(1,))\n",
    "    (conv2): Conv1d(32, 32, kernel_size=(1,), stride=(1,))\n",
    "    (conv3): Conv1d(32, 32, kernel_size=(1,), stride=(1,))\n",
    "    (maxpol): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "  )\n",
    "  (bn): BatchNorm1d(25, eps=1e-05, momentum=0.1, affine=True)\n",
    "  (fea1): Linear(in_features=25, out_features=64, bias=True)\n",
    "  (feares2): ResNet(\n",
    "    (lin1): Linear(in_features=64, out_features=64, bias=True)\n",
    "    (lin2): Linear(in_features=64, out_features=64, bias=True)\n",
    "  )\n",
    "  (fea3): Linear(in_features=64, out_features=64, bias=True)\n",
    "  (lin1): Linear(in_features=1664, out_features=1024, bias=True)\n",
    "  (res2): ResNet(\n",
    "    (lin1): Linear(in_features=1024, out_features=1024, bias=True)\n",
    "    (lin2): Linear(in_features=1024, out_features=1024, bias=True)\n",
    "  )\n",
    "  (res3): ResNet(\n",
    "    (lin1): Linear(in_features=1024, out_features=1024, bias=True)\n",
    "    (lin2): Linear(in_features=1024, out_features=1024, bias=True)\n",
    "  )\n",
    "  (lin3): Linear(in_features=1024, out_features=256, bias=True)\n",
    "  (res4): ResNet(\n",
    "    (lin1): Linear(in_features=256, out_features=256, bias=True)\n",
    "    (lin2): Linear(in_features=256, out_features=256, bias=True)\n",
    "  )\n",
    "  (res5): ResNet(\n",
    "    (lin1): Linear(in_features=256, out_features=256, bias=True)\n",
    "    (lin2): Linear(in_features=256, out_features=256, bias=True)\n",
    "  )\n",
    "  (lin8): Linear(in_features=256, out_features=3, bias=True)\n",
    ")```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After 10 epoch of training,\n",
    "\n",
    "The accuracy on the test set is: 0.743473224627996\n",
    "\n",
    "The cross-entropy on the test set is: 0.6006864595759783\n",
    "\n",
    "The confusion matrix is:\n",
    "```text\n",
    "array([[3404,  598,    7],\n",
    "       [ 453, 4488,  446],\n",
    "       [  44, 1331,  452]])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Generation Model\n",
    "Since we do not have most of the pitch/fx features. We average the feature from the training data grouped by pitcher,batter and pitch_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy on the test set is: 0.4631560188897799 <- 0.450325224984407\n",
    "\n",
    "The cross-entropy on the test set is: 1.7626901821693999 <- 1.7214855619830554\n",
    "\n",
    "The confusion matrix is:\n",
    "```text\n",
    "array([[ 130, 3624,  255],\n",
    "       [ 166, 4894,  327],\n",
    "       [  51, 1602,  174]])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep NN w/o Post Features\n",
    "We use the same structure as the previous model but with only the input features:\n",
    "```text\n",
    "'pitcher','batter','balls', 'strikes','inning','pitch_count'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After 5 epoch,\n",
    "\n",
    "The accuracy on the test set is: 0.48730286019780805\n",
    "\n",
    "The cross-entropy on the test set is: 0.9971903735363663\n",
    "\n",
    "The confusion matrix is:\n",
    "```text\n",
    "array([[ 846, 3163,    0],\n",
    "       [ 764, 4623,    0],\n",
    "       [ 290, 1537,    0]])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting, the model never predict the outcome as 'X'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
