{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature length:9\n",
      "Loading Data/MLB_2014/MLB_PitchFX_2014_RegularSeason.csv\n",
      "Loading Data/MLB_2014/MLB_PitchFX_2014_PostSeason.csv\n",
      "(658428, 12)\n",
      "(8837, 12)\n",
      "Loading Data/MLB_2015/MLB_PitchFX_2015_RegularSeason.csv\n",
      "(667265, 12)\n",
      "(672271, 12)\n",
      "Loading Data/MLB_2015/MLB_PitchFX_2015_PostSeason.csv\n",
      "(1339536, 12)\n",
      "(10277, 12)\n",
      "Loading Data/MLB_2016/MLB_PitchFX_2016_RegularSeason.csv\n",
      "(1349813, 12)\n",
      "(703809, 12)\n",
      "Loading Data/MLB_2016/MLB_PitchFX_2016_PostSeason.csv\n",
      "(2053622, 12)\n",
      "(10076, 12)\n"
     ]
    }
   ],
   "source": [
    "base_dir = \"Data/\"\n",
    "\n",
    "label2one = {'B':0,'S':1,'X':2, '<PAD>':3}\n",
    "one2label = {0:'B', 1:'S', 2:'X', 3:'<PAD>'}\n",
    "\n",
    "def normalize(data):\n",
    "    mu = np.mean(data, axis=0)\n",
    "    std = np.std(data, axis=0)\n",
    "    return mu, std, (data-mu)/std\n",
    "\n",
    "vfunc = np.vectorize(lambda x:label2one[x])\n",
    "\n",
    "#input_labels = ['pitcher','batter', 'pitch_type','x0','x','y','ax','ay','az','px','pz','sz_top','sz_bot',\n",
    "#             'vx0','vy0','vz0','pfx_x','z0','start_speed','end_speed',\n",
    "#             'break_y','break_angle','break_length','spin_dir','spin_rate',\n",
    "#             'inning','balls','strikes'\n",
    "#             ]\n",
    "#input_labels = ['pitcher','batter', 'pitch_type','balls', 'strikes','inning','pitch_count']\n",
    "input_labels = ['date','stadium', 'inning', 'side',\n",
    "                'pitcher','batter', \n",
    "               'on_1b', 'on_2b', 'on_3b', \n",
    "               'pitch_count', 'balls', 'strikes',\n",
    "#       'ay', 'px', 'ax',  \n",
    "#       'sz_bot', 'vz0', 'vy0', 'pfx_x',\n",
    "#       'type_confidence', 'z0', 'tfs', 'pz', 'start_speed', 'az', 'zone',\n",
    "#       'break_angle', 'spin_dir', 'end_speed', 'vx0', 'sz_top', 'nasty',\n",
    "#       'pfx_z', 'break_y', 'x', 'spin_rate',\n",
    "#       'y0', 'break_length', 'y', 'x0'\n",
    "      ]\n",
    "feature_length = len(input_labels)-3\n",
    "print(\"Feature length:{}\".format(feature_length))\n",
    "train_years = [4,5,6]\n",
    "dev_years = [7]\n",
    "\n",
    "\n",
    "train_x = {}\n",
    "train_y = {}\n",
    "ctr = 0\n",
    "for y in train_years:\n",
    "    filename= base_dir+\"MLB_201{0}/MLB_PitchFX_201{0}_RegularSeason.csv\".format(str(y))\n",
    "    print(\"Loading {}\".format(filename))\n",
    "    f = pd.read_csv(filename)\n",
    "    \n",
    "    tmp_x = f[input_labels]\n",
    "    tmp_y = f['umpcall']\n",
    "\n",
    "    tmp_x = tmp_x.as_matrix()\n",
    "    tmp_y = tmp_y.as_matrix()\n",
    "    tmp_y = vfunc(tmp_y)\n",
    "\n",
    "    if ctr==0:\n",
    "        ctr=1\n",
    "        train_x = tmp_x\n",
    "        train_y = tmp_y\n",
    "    else:\n",
    "        print(train_x.shape)\n",
    "        print(tmp_x.shape)\n",
    "        train_x = np.concatenate((train_x, tmp_x), axis=0)\n",
    "        train_y = np.concatenate((train_y, tmp_y), axis=0)\n",
    "    \n",
    "    filename= base_dir+\"MLB_201{0}/MLB_PitchFX_201{0}_PostSeason.csv\".format(str(y))\n",
    "    print(\"Loading {}\".format(filename))\n",
    "    f = pd.read_csv(filename)\n",
    "    \n",
    "    \n",
    "    tmp_x = f[input_labels]\n",
    "    tmp_y = f['umpcall']\n",
    "\n",
    "    tmp_x = tmp_x.as_matrix()\n",
    "    tmp_y = tmp_y.as_matrix()\n",
    "    tmp_y = vfunc(tmp_y)\n",
    "    if ctr==0:\n",
    "        ctr=1\n",
    "        train_x = tmp_x\n",
    "        train_y = tmp_y\n",
    "    else:\n",
    "        print(train_x.shape)\n",
    "        print(tmp_x.shape)\n",
    "        train_x = np.concatenate((train_x, tmp_x), axis=0)\n",
    "        train_y = np.concatenate((train_y, tmp_y), axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test file Data/MLB_2017/MLB_PitchFX_2017_RegularSeason.csv\n",
      "Loading test file Data/MLB_2017/MLB_PitchFX_2017_PostSeason.csv\n"
     ]
    }
   ],
   "source": [
    "filename = base_dir+\"MLB_2017/MLB_PitchFX_2017_RegularSeason.csv\"\n",
    "print(\"Loading test file {}\".format(filename))\n",
    "f2 = pd.read_csv(filename)\n",
    "\n",
    "test_x = f2[input_labels]\n",
    "test_y = f2['umpcall']\n",
    "\n",
    "test_x = test_x.as_matrix()\n",
    "test_y = test_y.as_matrix()\n",
    "test_y = vfunc(test_y)\n",
    "\n",
    "filename = base_dir+\"MLB_2017/MLB_PitchFX_2017_PostSeason.csv\"\n",
    "print(\"Loading test file {}\".format(filename))\n",
    "f2 = pd.read_csv(filename)\n",
    "\n",
    "tmp_x = f2[input_labels]\n",
    "tmp_y = f2['umpcall']\n",
    "\n",
    "tmp_x = tmp_x.as_matrix()\n",
    "tmp_y = tmp_y.as_matrix()\n",
    "tmp_y = vfunc(tmp_y)\n",
    "\n",
    "test_x = np.concatenate((test_x, tmp_x), axis=0)\n",
    "test_y = np.concatenate((test_y, tmp_y), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_GAME_LEN = 597"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# String to Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        \"\"\"Init Lang with a name.\"\"\"\n",
    "        self.name = name\n",
    "        self.word2index = {\"<UNK>\": 0, '<EMP>':1}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"<UNK>\", 1:'<EMP>'}\n",
    "        self.n_words = len(self.word2index)  # Count SOS and EOS\n",
    "\n",
    "    def addword(self, word):\n",
    "        \"\"\"Add a word to the dict.\"\"\"\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['date',\n",
       " 'stadium',\n",
       " 'inning',\n",
       " 'side',\n",
       " 'pitcher',\n",
       " 'batter',\n",
       " 'on_1b',\n",
       " 'on_2b',\n",
       " 'on_3b',\n",
       " 'pitch_count',\n",
       " 'balls',\n",
       " 'strikes']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "players = Lang('players')\n",
    "loc = Lang('stadium')\n",
    "dt = Lang('date')\n",
    "sd = Lang('side')\n",
    "\n",
    "for i in range(train_x.shape[0]):\n",
    "    loc.addword(train_x[i,1])    \n",
    "    sd.addword(train_x[i,3])\n",
    "    players.addword(train_x[i,4])\n",
    "    players.addword(train_x[i,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mat2ind(x):\n",
    "    def findindex(s,lan):\n",
    "        try:\n",
    "            return lan.word2index[s]\n",
    "        except KeyError:\n",
    "            return lan.word2index['<UNK>']\n",
    "    n_train_x = np.zeros((x.shape[0], x.shape[1]+2))\n",
    "    for i in range(x.shape[0]):\n",
    "        n_train_x[i,0] = int(x[i,0][5:7]) # month\n",
    "        n_train_x[i,1] = int(x[i,0][8:]) # day\n",
    "        n_train_x[i,2] = findindex(x[i,1], loc) # stadium\n",
    "\n",
    "        n_train_x[i,3] = x[i,2] # inning\n",
    "\n",
    "        n_train_x[i,4] = 1 if x[i,3]=='top' else -1 # side\n",
    "        n_train_x[i,5] = findindex(x[i,4], players) # pitcher\n",
    "        n_train_x[i,6] = findindex(x[i,5], players) # batter\n",
    "        n_train_x[i,7] = findindex('<EMP>', players) if isinstance(x[i,6],float) and math.isnan(x[i,6]) else findindex(x[i,6], players)\n",
    "        n_train_x[i,8] = findindex('<EMP>', players)if isinstance(x[i,7],float) and math.isnan(x[i,7]) else findindex(x[i,7], players)\n",
    "        n_train_x[i,9] = findindex('<EMP>', players) if isinstance(x[i,8],float) and math.isnan(x[i,8]) else findindex(x[i,8], players)\n",
    "    return n_train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx = mat2ind(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntx = mat2ind(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNextGame(f):\n",
    "    ctr = 0\n",
    "    ptr = ctr\n",
    "    while ctr < f.shape[0]:\n",
    "        prev_inn = 0\n",
    "        while ptr < f.shape[0] and f[ctr,0] == f[ptr,0] and f[ctr,1]== f[ptr,1] \\\n",
    "                and f[ctr,2] == f[ptr,2] and f[ptr,3]>=prev_inn :\n",
    "            prev_inn = f[ptr,3]\n",
    "            ptr+=1\n",
    "        yield ctr,ptr\n",
    "        ctr = ptr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7388\n"
     ]
    }
   ],
   "source": [
    "game_ctr = 0\n",
    "for c,p  in getNextGame(nx):\n",
    "    game_ctr +=1\n",
    "print(game_ctr)\n",
    "ntrain_x = np.zeros((game_ctr, MAX_GAME_LEN, nx.shape[1]))\n",
    "ntrain_y = np.ones((game_ctr, MAX_GAME_LEN, 1)) * 3\n",
    "ctr=0\n",
    "for c,p  in getNextGame(nx):\n",
    "    ntrain_x[ctr,:p-c,:] = nx[c:p,:]\n",
    "    ntrain_y[ctr,:p-c,0] = train_y[c:p]\n",
    "    ctr+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2466\n"
     ]
    }
   ],
   "source": [
    "game_ctr = 0\n",
    "for c,p  in getNextGame(ntx):\n",
    "    game_ctr +=1\n",
    "print(game_ctr)\n",
    "ntest_x = np.zeros((game_ctr, MAX_GAME_LEN, ntx.shape[1]))\n",
    "ntest_y = np.ones((game_ctr, MAX_GAME_LEN, 1))*3\n",
    "ctr=0\n",
    "for c,p  in getNextGame(ntx):\n",
    "    ntest_x[ctr,:p-c,:] = ntx[c:p,:]\n",
    "    ntest_y[ctr,:p-c,0] = test_y[c:p]\n",
    "    ctr+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_gen(dx, dy, batch_size=100):\n",
    "    idx = 0\n",
    "    while True:\n",
    "        if idx*batch_size >= dx.shape[0]:\n",
    "            return\n",
    "        elif (idx+1)*batch_size > dx.shape[0]:\n",
    "            yield dx[idx*batch_size:,:], dy[idx*batch_size:]\n",
    "        else:\n",
    "            yield dx[idx*batch_size:(idx+1)*batch_size,:], dy[idx*batch_size:(idx+1)*batch_size]\n",
    "        idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlayerEmbedding(nn.Module):\n",
    "    def __init__(self, stadium_size, player_size, emb_dim, sta_dim):\n",
    "        super(PlayerEmbedding, self).__init__()\n",
    "        mon_size = 100\n",
    "        day_size = 100\n",
    "        self.emb_mon = nn.Embedding(13, mon_size)\n",
    "        self.emb_day = nn.Embedding(32, day_size)\n",
    "        self.emb_player = nn.Embedding(player_size, emb_dim)\n",
    "        self.emb_stadium = nn.Embedding(stadium_size, sta_dim)\n",
    "        \n",
    "        self.emb_dim = mon_size+day_size + sta_dim + 5*emb_dim\n",
    "\n",
    "    def forward(self, mon, day, stadium, p, b, onb1,onb2,onb3):\n",
    "        e_mon = self.emb_mon(mon)\n",
    "        e_day = self.emb_day(day)\n",
    "        emb_s = self.emb_stadium(stadium)\n",
    "        emb_p = self.emb_player(p)\n",
    "        emb_b = self.emb_player(b)\n",
    "        emb_b1 = self.emb_player(onb1)\n",
    "        emb_b2 = self.emb_player(onb2)\n",
    "        emb_b3 = self.emb_player(onb3)\n",
    "        \n",
    "        \n",
    "\n",
    "        emb_all = torch.cat([e_mon, e_day, emb_s, emb_p, emb_b, emb_b1, emb_b2, emb_b3], dim=2)\n",
    "        return emb_all\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        em_layer = [self.emb_mon, self.emb_day, self.emb_player, self.emb_stadium]\n",
    "\n",
    "        for layer in em_layer:\n",
    "            #layer.weight.data.normal_(0, initrange)\n",
    "            layer.weight.data.uniform_(-initrange, initrange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    \"\"\"Vanilla encoder using pure LSTM.\"\"\"\n",
    "    def __init__(self, hidden_size, embedding_layer, dp=0.1, n_layers=2):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = embedding_layer\n",
    "        #self.dp1 = nn.Dropout(dp)\n",
    "        self.lstm = nn.LSTM(self.embedding.emb_dim, hidden_size , num_layers=n_layers, dropout=dp, bidirectional=False)\n",
    "        self.lin1 = nn.Linear(self.hidden_size, self.hidden_size)\n",
    "        self.lin2 = nn.Linear(self.hidden_size, 3)\n",
    "\n",
    "    def forward(self, inp, hidden):\n",
    "        '''\n",
    "        inputs: (batch_size, seq_len, feature_dim)\n",
    "        '''\n",
    "        embedded = self.embedding(inp[:,:,0], inp[:,:,1], inp[:,:,2], inp[:,:,5], inp[:,:,6], inp[:,:,7], inp[:,:,8], inp[:,:,9])\n",
    "        \n",
    "        embedded = embedded.permute(1,0,2)\n",
    "        bilstm_outs, nh = self.lstm(embedded, hidden)\n",
    "        \n",
    "        output = bilstm_outs.permute(1,0,2)\n",
    "        # (batch, seq_len, hidden)\n",
    "        #output = F.relu(self.lin1(output))\n",
    "        output = self.lin2(output)\n",
    "        # (batch, seq_len, 3)\n",
    "        return F.log_softmax(output, dim=2)\n",
    "\n",
    "    def initHidden(self, batch_size):\n",
    "        forward = Variable(torch.zeros(self.n_layers, batch_size, self.hidden_size )).to(DEVICE)\n",
    "        backward = Variable(torch.zeros(self.n_layers, batch_size, self.hidden_size )).to(DEVICE)\n",
    "        return (forward, backward)\n",
    "        #return forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_x, train_y, dev_x, dev_y, model, optimizer, criterion, batch_size=512, \n",
    "          max_epoch = 512, validation_interv=1000, show_iter=10):\n",
    "    start = time.time()\n",
    "    for ep in range(max_epoch):\n",
    "        print(\"Epoch {}\".format(ep))\n",
    "        model.train()\n",
    "\n",
    "        train_iter = data_gen(train_x, train_y, batch_size=batch_size)\n",
    "\n",
    "        ctr = 0\n",
    "        avg_loss = 0\n",
    "        acc = 0\n",
    "        iteration = 0\n",
    "        for bx,by in train_iter:\n",
    "            iteration +=1\n",
    "            optimizer.zero_grad()\n",
    "            model.train()\n",
    "            hid = model.initHidden(bx.shape[0])\n",
    "            y_pred = model(bx, hid)\n",
    "            \n",
    "            y_pred = y_pred.view(y_pred.shape[0] * y_pred.shape[1],-1)\n",
    "            by = by.view(by.shape[0]*by.shape[1])\n",
    "            \n",
    "            idx = (by!=3)\n",
    "            y_pred = y_pred[idx,:]\n",
    "            by = by[idx]\n",
    "\n",
    "            _, lab_y = torch.max(y_pred, 1)\n",
    "            \n",
    "            \n",
    "            loss = criterion(y_pred, by)\n",
    "            acc += torch.sum(lab_y == by).item()\n",
    "            loss.backward()\n",
    "            avg_loss += loss.item()*by.shape[0]\n",
    "            optimizer.step()\n",
    "            ctr+= by.shape[0]\n",
    "            if iteration % show_iter == 0:\n",
    "                print(\"Time: {}, iter: {}, avg. loss: {}, avg.acc: {}\".format(time.time() - start, \n",
    "                                                                              iteration,  \n",
    "                                                                              avg_loss/ctr,\n",
    "                                                                              acc/ctr))\n",
    "                avg_loss = 0\n",
    "                ctr = 0\n",
    "                acc = 0\n",
    "        #dy_pred = model(dev_x, dev_f)\n",
    "        \n",
    "        lo, ac = calPerf(dev_x, dev_y, model, criterion, batch_size)\n",
    "        \n",
    "\n",
    "        print(\"Time: {}, loss:{} dev_loss:{}, dev_acc:{}\".format(time.time() - start, avg_loss/ctr, lo, ac))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calPerf(dev_x, dev_y, model, criterion, batch_size=16):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        ll = 0\n",
    "        ctrr = 0\n",
    "        acc = 0\n",
    "        for dx,dy in data_gen(dev_x, dev_y, batch_size=batch_size):\n",
    "            hid = model.initHidden(dx.shape[0])\n",
    "            dy_pred = model(dx, hid)\n",
    "\n",
    "            dy_pred = dy_pred.view(dy_pred.shape[0] * dy_pred.shape[1], -1)\n",
    "            dy = dy.view(dy.shape[0]*dy.shape[1])\n",
    "\n",
    "            idx = (dy!=3)\n",
    "            dy_pred = dy_pred[idx,:]\n",
    "            dy = dy[idx]\n",
    "\n",
    "            loss = criterion(dy_pred, dy)\n",
    "\n",
    "            ll += loss * dy.shape[0]\n",
    "            ctrr += dy.shape[0]\n",
    "            _, lab_y = torch.max(dy_pred, 1)\n",
    "\n",
    "            acc += torch.sum( lab_y == dy ).item()\n",
    "    return ll/ctrr, acc/ctrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_x, dev_x, train_y, dev_y = train_test_split(ntrain_x, ntrain_y, test_size=0.1, random_state=0, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vtrainx = Variable(torch.from_numpy(train_x.astype(np.long)), requires_grad=False).to(DEVICE)\n",
    "vtrainy = Variable(torch.from_numpy(train_y.astype(np.long)), requires_grad=False).to(DEVICE)\n",
    "\n",
    "vdevx = Variable(torch.from_numpy(dev_x.astype(np.long)), requires_grad=False).to(DEVICE)\n",
    "vdevy = Variable(torch.from_numpy(dev_y.astype(np.long)), requires_grad=False).to(DEVICE)\n",
    "vtestx = Variable(torch.from_numpy(ntest_x.astype(np.long)), requires_grad=False).to(DEVICE)\n",
    "vtesty = Variable(torch.from_numpy(ntest_y.astype(np.long)), requires_grad=False).to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM(\n",
      "  (embedding): PlayerEmbedding(\n",
      "    (emb_mon): Embedding(13, 100)\n",
      "    (emb_day): Embedding(32, 100)\n",
      "    (emb_player): Embedding(1880, 256)\n",
      "    (emb_stadium): Embedding(34, 10)\n",
      "  )\n",
      "  (lstm): LSTM(1490, 1024, num_layers=2, dropout=0.1)\n",
      "  (lin1): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "  (lin2): Linear(in_features=1024, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "emb = PlayerEmbedding(loc.n_words, players.n_words, 256,10).to(DEVICE)\n",
    "model = LSTM(1024, emb, n_layers=2).to(DEVICE)\n",
    "print(model)\n",
    "#opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "opt = torch.optim.Adagrad(model.parameters(), lr=0.01, lr_decay=0, weight_decay=0)\n",
    "crit = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Time: 8.100097179412842, iter: 10, avg. loss: 1.0192512735363184, avg.acc: 0.46384446465408247\n",
      "Time: 16.190094470977783, iter: 20, avg. loss: 1.0165523647985344, avg.acc: 0.4672524314765694\n",
      "Time: 24.287427186965942, iter: 30, avg. loss: 1.020094162184382, avg.acc: 0.46290904594354576\n",
      "Time: 32.388426065444946, iter: 40, avg. loss: 1.0208407819634029, avg.acc: 0.46146184666229034\n",
      "Time: 40.49259281158447, iter: 50, avg. loss: 1.019300871879167, avg.acc: 0.46260222059703476\n",
      "Time: 48.588518142700195, iter: 60, avg. loss: 1.0205040306542321, avg.acc: 0.46408578943818707\n",
      "Time: 56.673378467559814, iter: 70, avg. loss: 1.0178048831726099, avg.acc: 0.46380967315576066\n",
      "Time: 64.75835752487183, iter: 80, avg. loss: 1.0190694754530807, avg.acc: 0.46221002182570936\n",
      "Time: 72.8707582950592, iter: 90, avg. loss: 1.018124907389625, avg.acc: 0.4625176491351924\n",
      "Time: 81.1646990776062, iter: 100, avg. loss: 1.0190161175873342, avg.acc: 0.4631992149165849\n",
      "Time: 89.48227906227112, iter: 110, avg. loss: 1.0184913077979705, avg.acc: 0.46373246160931936\n",
      "Time: 97.56807684898376, iter: 120, avg. loss: 1.0194102648754892, avg.acc: 0.4621445815450644\n",
      "Time: 105.65494322776794, iter: 130, avg. loss: 1.0160993454894711, avg.acc: 0.4663962855844775\n",
      "Time: 113.73142576217651, iter: 140, avg. loss: 1.0208582523014993, avg.acc: 0.4601038609166855\n",
      "Time: 121.9538505077362, iter: 150, avg. loss: 1.0174211576873338, avg.acc: 0.46247532371934286\n",
      "Time: 130.02705430984497, iter: 160, avg. loss: 1.0182877368025085, avg.acc: 0.4626132802335185\n",
      "Time: 138.10739135742188, iter: 170, avg. loss: 1.0152203287186392, avg.acc: 0.4666894581867508\n",
      "Time: 146.20822834968567, iter: 180, avg. loss: 1.0158020538370638, avg.acc: 0.46261728943423464\n",
      "Time: 154.2783706188202, iter: 190, avg. loss: 1.0169620999475089, avg.acc: 0.46326068433562045\n",
      "Time: 162.58200860023499, iter: 200, avg. loss: 1.0152178505205158, avg.acc: 0.46471846834362496\n",
      "Time: 175.23411655426025, loss:1.015283228644661 dev_loss:1.0320042371749878, dev_acc:0.4556535156458492\n",
      "Epoch 1\n",
      "Time: 183.1059045791626, iter: 10, avg. loss: 1.0162018883953612, avg.acc: 0.46459862919504025\n",
      "Time: 191.18742394447327, iter: 20, avg. loss: 1.0122802504691584, avg.acc: 0.4691534040671972\n",
      "Time: 199.54789185523987, iter: 30, avg. loss: 1.0163217453449143, avg.acc: 0.465303461222838\n",
      "Time: 207.8779821395874, iter: 40, avg. loss: 1.016133314963823, avg.acc: 0.4650044140616158\n",
      "Time: 216.03803730010986, iter: 50, avg. loss: 1.0150658137234587, avg.acc: 0.465538638831638\n",
      "Time: 224.20590496063232, iter: 60, avg. loss: 1.0159872500553575, avg.acc: 0.46612036599896584\n",
      "Time: 232.36637496948242, iter: 70, avg. loss: 1.0139204207392598, avg.acc: 0.4667779296131186\n",
      "Time: 240.53753471374512, iter: 80, avg. loss: 1.0145764101544859, avg.acc: 0.46713768197466415\n",
      "Time: 248.6886510848999, iter: 90, avg. loss: 1.0134557125859154, avg.acc: 0.4637310271796682\n",
      "Time: 256.8748767375946, iter: 100, avg. loss: 1.0144290515802825, avg.acc: 0.46663395485770365\n",
      "Time: 265.0440866947174, iter: 110, avg. loss: 1.0145031843385868, avg.acc: 0.4665857850571226\n",
      "Time: 273.20325994491577, iter: 120, avg. loss: 1.0153533377456818, avg.acc: 0.46556464592274677\n",
      "Time: 281.3687310218811, iter: 130, avg. loss: 1.01187714248859, avg.acc: 0.46667331538180246\n",
      "Time: 289.52195930480957, iter: 140, avg. loss: 1.017085281527858, avg.acc: 0.46362610069993226\n",
      "Time: 297.6793968677521, iter: 150, avg. loss: 1.0139330552754182, avg.acc: 0.46350141086983193\n",
      "Time: 305.83097100257874, iter: 160, avg. loss: 1.0131302653103826, avg.acc: 0.46475160374263186\n",
      "Time: 313.96663427352905, iter: 170, avg. loss: 1.011730874200139, avg.acc: 0.4690935959504615\n",
      "Time: 322.116886138916, iter: 180, avg. loss: 1.0124744847576554, avg.acc: 0.465937482649492\n",
      "Time: 330.2499656677246, iter: 190, avg. loss: 1.0113914420123142, avg.acc: 0.4665343737387327\n",
      "Time: 338.55767345428467, iter: 200, avg. loss: 1.0107426096110772, avg.acc: 0.4680775583960622\n",
      "Time: 351.31429076194763, loss:1.010073273119572 dev_loss:1.036464810371399, dev_acc:0.4440519571261518\n",
      "Epoch 2\n",
      "Time: 359.52912187576294, iter: 10, avg. loss: 1.0113385804513966, avg.acc: 0.4676152873588714\n",
      "Time: 367.8866698741913, iter: 20, avg. loss: 1.0065586276438045, avg.acc: 0.4724248452696729\n",
      "Time: 376.04033160209656, iter: 30, avg. loss: 1.012081009040402, avg.acc: 0.46929415335499175\n",
      "Time: 384.2060663700104, iter: 40, avg. loss: 1.0106471298068906, avg.acc: 0.4678565769518075\n",
      "Time: 392.3557472229004, iter: 50, avg. loss: 1.0103900728159556, avg.acc: 0.47068014094807525\n",
      "Time: 400.4738676548004, iter: 60, avg. loss: 1.0114589472264686, avg.acc: 0.46858209122996336\n",
      "Time: 408.6387746334076, iter: 70, avg. loss: 1.0081476101768163, avg.acc: 0.4706646654270929\n",
      "Time: 416.7811541557312, iter: 80, avg. loss: 1.0095717508671154, avg.acc: 0.4661589001642553\n",
      "Time: 424.90881180763245, iter: 90, avg. loss: 1.0077021651330282, avg.acc: 0.46860660077656197\n",
      "Time: 433.1719093322754, iter: 100, avg. loss: 1.0091842621089437, avg.acc: 0.46946390670287785\n",
      "Time: 441.13887000083923, iter: 110, avg. loss: 1.0100739275225747, avg.acc: 0.47065233264808637\n",
      "Time: 449.05941581726074, iter: 120, avg. loss: 1.0090989253513025, avg.acc: 0.46983413805436336\n",
      "Time: 457.1031811237335, iter: 130, avg. loss: 1.0050734328091289, avg.acc: 0.47154903981472246\n",
      "Time: 465.1054267883301, iter: 140, avg. loss: 1.0127353239002925, avg.acc: 0.4666403251298262\n",
      "Time: 473.04793190956116, iter: 150, avg. loss: 1.0082221970599807, avg.acc: 0.46823033425904237\n",
      "Time: 480.9619390964508, iter: 160, avg. loss: 1.0065066145713886, avg.acc: 0.46970708362089447\n",
      "Time: 488.86698722839355, iter: 170, avg. loss: 1.0072827301467957, avg.acc: 0.473493829747345\n",
      "Time: 496.77045607566833, iter: 180, avg. loss: 1.006197952808528, avg.acc: 0.4698684137471545\n",
      "Time: 504.66544485092163, iter: 190, avg. loss: 1.0072434883643395, avg.acc: 0.4676106551863312\n",
      "Time: 512.5732724666595, iter: 200, avg. loss: 1.004055101465796, avg.acc: 0.4711151513807745\n",
      "Time: 524.7552425861359, loss:1.004955630396205 dev_loss:1.037829875946045, dev_acc:0.4535573745833192\n"
     ]
    }
   ],
   "source": [
    "train(vtrainx, vtrainy, vdevx, vdevy, model, opt, crit, batch_size=32, max_epoch=3, show_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calPred(dev_x, dev_y, model, criterion, batch_size=16):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        ll = 0\n",
    "        ctrr = 0\n",
    "        acc = 0\n",
    "        for dx,dy in data_gen(dev_x, dev_y, batch_size=batch_size):\n",
    "            hid = model.initHidden(dx.shape[0])\n",
    "            dy_pred = model(dx, hid)\n",
    "\n",
    "            dy_pred = dy_pred.view(dy_pred.shape[0] * dy_pred.shape[1], -1)\n",
    "            dy = dy.view(dy.shape[0]*dy.shape[1])\n",
    "\n",
    "            idx = (dy!=3)\n",
    "            dy_pred = dy_pred[idx,:]\n",
    "            dy = dy[idx]\n",
    "\n",
    "            loss = criterion(dy_pred, dy)\n",
    "\n",
    "            ll += loss * dy.shape[0]\n",
    "            ctrr += dy.shape[0]\n",
    "            _, lab_y = torch.max(dy_pred, 1)\n",
    "\n",
    "            acc += torch.sum( lab_y == dy ).item()\n",
    "    return ll/ctrr, acc/ctrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1.0353, device='cuda:0'), 0.4543989762782762)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calPerf(vtestx, vtesty,model,crit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "424"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countMaxLen(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date       True\n",
       "stadium    True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.iloc[291, 0:2] == f.iloc[292, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.iloc[292, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
